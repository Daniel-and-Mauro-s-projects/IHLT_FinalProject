{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Exercise 1: Daniel Macsai & Mauro Vázquez Chas"],"metadata":{"id":"GtMCpQNXs17m"}},{"cell_type":"code","source":["import nltk\n","nltk.download('gutenberg') #we import a corpus (large and structured set of textual data that is used to train the model, documents, articles, books...)\n","nltk.download('stopwords') #we import the list of stopwords (words that dont add meaning)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSUaGFINt8gs","executionInfo":{"status":"ok","timestamp":1726163954716,"user_tz":-120,"elapsed":545,"user":{"displayName":"Mauro Vázquez Chas","userId":"09295638050179013463"}},"outputId":"2a2f9380-2e40-4dc6-da2b-0b7e90f111e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":240}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIIswRr4swbL"},"outputs":[],"source":["nltk.corpus.gutenberg.fileids()\n","txt = nltk.corpus.gutenberg.words('blake-poems.txt') #we extract a document in particular from the corpus"]},{"cell_type":"code","source":["stop = nltk.corpus.stopwords.words('english') #select just english stopwords"],"metadata":{"id":"LoWJhGD8xm7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["txt = list(map(lambda x : x.lower(), txt)) #put it in lowcase"],"metadata":{"id":"ybCnkai8x9RA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stop.extend([\".\", \",\", \"(\", \")\", \"[\",\"]\", \":\", \";\", '\"',\"'\",\"?\",\"!\",'-','.\"','&']) #add problematic symbols"],"metadata":{"id":"A8vT-NzvzfNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#we remove stopwords\n","for word in stop:\n","    txt = [x for x in txt if x != word]"],"metadata":{"id":"10J_jeoq0Re6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# frequencies of words\n","freqs = {w:txt.count(w) for w in set(txt)}\n","top25_txt=list(sorted(freqs.items(), key=lambda item: item[1], reverse = True))[:25]\n","top25_txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H41XZoH51K-O","executionInfo":{"status":"ok","timestamp":1726163955489,"user_tz":-120,"elapsed":12,"user":{"displayName":"Mauro Vázquez Chas","userId":"09295638050179013463"}},"outputId":"c9f3cef5-beb1-41cc-8233-38a5e583db60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('little', 45),\n"," ('thee', 42),\n"," ('like', 35),\n"," ('thou', 35),\n"," ('thy', 31),\n"," ('love', 29),\n"," ('sweet', 28),\n"," ('night', 28),\n"," ('joy', 25),\n"," ('away', 24),\n"," ('weep', 24),\n"," ('father', 22),\n"," ('sleep', 21),\n"," ('shall', 19),\n"," ('happy', 19),\n"," ('day', 19),\n"," ('mother', 19),\n"," ('child', 18),\n"," ('every', 17),\n"," ('never', 17),\n"," ('see', 16),\n"," ('er', 16),\n"," ('voice', 16),\n"," ('human', 16),\n"," ('green', 16)]"]},"metadata":{},"execution_count":246}]},{"cell_type":"markdown","source":["#Conclusion"],"metadata":{"id":"Gpc1gH4e3q2S"}},{"cell_type":"markdown","source":["The whole list may not be perfect because we added some more symbols other than the stopwords by hand for the removal: we might have left out some of them. Some of the words in the 25 most common seem to be old words, which are no longer in use, such as \"er\", \"thy\", \"thou\", \"thee\". In Python, dictionaries do not have positions in the way that lists or tuples, that is why at the end we converted the dictionary to a list, in order to be safe. Having said this, from Python 3.7 and upwards dictionaries keep the insertion order."],"metadata":{"id":"xsXKoh2K3tkF"}}]}