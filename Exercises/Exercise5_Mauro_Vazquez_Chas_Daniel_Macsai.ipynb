{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13113,"status":"ok","timestamp":1729112389838,"user":{"displayName":"Mauro Vázquez Chas","userId":"09295638050179013463"},"user_tz":-120},"id":"T9sxHrYghtQT","outputId":"54c2d6f6-50be-4483-e56a-91c24b08cec2"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /home/mauro/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /home/mauro/nltk_data...\n","[nltk_data] Downloading package semcor to /home/mauro/nltk_data...\n"]}],"source":["import nltk\n","nltk.download(\"wordnet\")\n","from nltk.corpus import wordnet as wn\n","nltk.download(\"omw-1.4\")\n","nltk.download('semcor')\n","from nltk.corpus import semcor\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{"id":"NLHNUvMHHujH"},"source":["# Finding the most frequent WordNet synset for each word (when possible)"]},{"cell_type":"markdown","metadata":{"id":"QJixwA8m68hP"},"source":["For this, we found some contradicting information. One source said, that if we get the Synsets for a word, they are already ordered by their frequencies, and others said that this is not the case. Just to be sure, we searched for a pre-tagged corpus to sample from, to find the accurate frequencies for each synset corresponding to a word. We chose the SemCor corpus for this."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1729112389839,"user":{"displayName":"Mauro Vázquez Chas","userId":"09295638050179013463"},"user_tz":-120},"id":"2M9xfD2UHvwq"},"outputs":[],"source":["# Convert POS tags into another system\n","def get_wordnet_pos(category):\n","  if category.startswith('J'):\n","    return 'a'  # Adjective\n","  elif category.startswith('V'):\n","    return 'v'  # Verb\n","  elif category.startswith('N'):\n","    return 'n'  # Noun\n","  elif category.startswith('R'):\n","    return 'r'  # Adverb\n","  else:\n","    return None  # WordNet doesn't handle other POS tags\n","\n","word_tag_pairs = [\n","('the', 'DT'), ('man', 'NN'), ('swim', 'VB'), ('with', 'PR'), ('a', 'DT'),\n","('girl', 'NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n","('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')\n","]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502961,"status":"ok","timestamp":1729113054149,"user":{"displayName":"Mauro Vázquez Chas","userId":"09295638050179013463"},"user_tz":-120},"id":"RzuzDlhOrb_I","outputId":"771cdda7-685b-4d69-c703-e3bcea8a48e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","No DT synsets found for 'the' in SemCor\n","\n","Most frequent NN synset for 'man': Synset('man.n.01')\n","Definition: an adult person who is male (as opposed to a woman)\n","Frequency: 429\n","\n","Most frequent VB synset for 'swim': Synset('swim.v.01')\n","Definition: travel through water\n","Frequency: 12\n","\n","No PR synsets found for 'with' in SemCor\n","\n","No DT synsets found for 'a' in SemCor\n","\n","Most frequent NN synset for 'girl': Synset('girl.n.01')\n","Definition: a young woman\n","Frequency: 77\n","\n","No CC synsets found for 'and' in SemCor\n","\n","No DT synsets found for 'a' in SemCor\n","\n","Most frequent NN synset for 'boy': Synset('male_child.n.01')\n","Definition: a youthful male person\n","Frequency: 135\n","\n","No PR synsets found for 'whilst' in SemCor\n","\n","No DT synsets found for 'the' in SemCor\n","\n","Most frequent NN synset for 'woman': Synset('woman.n.01')\n","Definition: an adult female person (as opposed to a man)\n","Frequency: 137\n","\n","Most frequent VB synset for 'walk': Synset('walk.v.01')\n","Definition: use one's feet to advance; advance by steps\n","Frequency: 163\n"]}],"source":["filtered_synsets=[]\n","for target_word, target_pos in word_tag_pairs:\n","  synset_counts = Counter()\n","  # Iterate through tagged sentences in the SemCor corpus\n","  for sentence in semcor.tagged_sents(tag='sem'):\n","      for word in sentence:\n","          # Check if the word is a tagged WordNet synset\n","          if isinstance(word, nltk.tree.tree.Tree):\n","              synset = word.label()\n","              if synset and isinstance(synset, nltk.corpus.reader.wordnet.Lemma):\n","                  # If the lemma matches the target word and synset is the correct category, count it\n","                  if synset.name().lower() == target_word and synset.synset().pos() == get_wordnet_pos(target_pos):\n","                      synset_counts[synset.synset()] += 1\n","\n","  # Find the most frequent synset\n","  if synset_counts:\n","      most_common_synset, frequency = synset_counts.most_common(1)[0]\n","      filtered_synsets=filtered_synsets+[most_common_synset]\n","      print(f\"\\nMost frequent {target_pos} synset for '{target_word}': {most_common_synset}\")\n","      print(f\"Definition: {most_common_synset.definition()}\")\n","      print(f\"Frequency: {frequency}\")\n","  else:\n","      print(f\"\\nNo {target_pos} synsets found for '{target_word}' in SemCor\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1729111572478,"user":{"displayName":"Dániel Mácsai","userId":"14906705828771596691"},"user_tz":-120},"id":"_8IIhX0E7tfw","outputId":"0d86b6cb-5ab4-44d3-eb66-27c4d60de958"},"outputs":[{"data":{"text/plain":["[Synset('man.n.01'),\n"," Synset('swim.v.01'),\n"," Synset('girl.n.01'),\n"," Synset('male_child.n.01'),\n"," Synset('woman.n.01'),\n"," Synset('walk.v.01')]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["filtered_synsets"]},{"cell_type":"markdown","metadata":{"id":"cKlXFj5xl_Ai"},"source":["* First we converted the pos tag to wordnet values. We have to take into account that wordnet only has nouns, verbs, adjectives and adverbs (words with substantial meaning) so any other category of word won't have a synset in wordnet.\n","* After that we counted the number of apperances of synsets for the needed words in the SemCor corpus (with the matching POS tag) and saved the most common one.\n","* In these cases, the most common ones are also the first ones (since they end with .01), so the above hypothesis still holds."]},{"cell_type":"markdown","metadata":{"id":"GMJVUkk7Mtui"},"source":["# For each pair of words, when possible, print their corresponding least common subsumer (LCS) and their similarity value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVZC-J6jMvPn"},"outputs":[],"source":["# Get all posible combinations:\n","from itertools import combinations\n","def get_all_pairs(lst):\n","  return list(combinations(lst, 2))\n","\n","pairs=get_all_pairs(filtered_synsets)"]},{"cell_type":"markdown","metadata":{"id":"-lcKZTcumr-Y"},"source":["* We create a list with all the posible pairs of synsets and afterwards we filter the ones with the same pos tag. This is required because the trees from wordnet are different for each category of words and we can't compute the similarities or LCS if they are not on the same tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-S4xbkPYrIn"},"outputs":[],"source":["# We can just compute the similarities and LCS of synsets with the same pos:\n","valid_pairs= [pair for pair in pairs if pair[0].pos()==pair[1].pos()]"]},{"cell_type":"markdown","metadata":{"id":"Q9k3eW1gnJs_"},"source":["* For the Lin similarity calculation we decided to use the information content from the brown corpus."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1729111572479,"user":{"displayName":"Dániel Mácsai","userId":"14906705828771596691"},"user_tz":-120},"id":"pTDEmIE-fOLy","outputId":"6107e85f-614e-43c6-ae43-4f76e9db7304"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet_ic to /home/mauro/nltk_data...\n","[nltk_data]   Package wordnet_ic is already up-to-date!\n"]}],"source":["# we import the information component from the brown corpus:\n","nltk.download('wordnet_ic')\n","from nltk.corpus import wordnet_ic\n","ic_brown = wordnet_ic.ic('ic-brown.dat')"]},{"cell_type":"markdown","metadata":{"id":"ua0LJ_7q__E-"},"source":["We calculated the ranges for the different similarity metrics based on the formulas from the class, and we found that the Path, Wu-Palmer and Lin similarities are all contained in the [0, 1] range, so we only need to normalize the Leacock-Chodorow similarity, since it takes values in the $[0, log_2(2 \\text{MaxDepth})]$ interval. We normalize this by dividing with the similarity value we get when comparing a synset with itself."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1470,"status":"ok","timestamp":1729111756287,"user":{"displayName":"Dániel Mácsai","userId":"14906705828771596691"},"user_tz":-120},"id":"bbJ7ysS4RQsf","outputId":"01f5d374-8e45-4fab-ca67-940d1716d944"},"outputs":[{"name":"stdout","output_type":"stream","text":["The normalizing value for Leacock-Chodorow is:  3.6375861597263857\n","\n","Computing LCS and Similarities for pair: (Synset('man.n.01'), Synset('girl.n.01'))\n","LCS for 'Synset('man.n.01')' and 'Synset('girl.n.01')': [Synset('adult.n.01')]\n","Path Similarity: 0.25\n","Leacock-Chodorow Similarity: 0.6188971751464533\n","Wu-Palmer Similarity: 0.631578947368421\n","Lin Similarity: 0.7135111237276783\n","\n","Computing LCS and Similarities for pair: (Synset('man.n.01'), Synset('male_child.n.01'))\n","LCS for 'Synset('man.n.01')' and 'Synset('male_child.n.01')': [Synset('male.n.02')]\n","Path Similarity: 0.3333333333333333\n","Leacock-Chodorow Similarity: 0.6979831568441128\n","Wu-Palmer Similarity: 0.6666666666666666\n","Lin Similarity: 0.7294717876200584\n","\n","Computing LCS and Similarities for pair: (Synset('man.n.01'), Synset('woman.n.01'))\n","LCS for 'Synset('man.n.01')' and 'Synset('woman.n.01')': [Synset('adult.n.01')]\n","Path Similarity: 0.3333333333333333\n","Leacock-Chodorow Similarity: 0.6979831568441128\n","Wu-Palmer Similarity: 0.6666666666666666\n","Lin Similarity: 0.7870841372982784\n","\n","Computing LCS and Similarities for pair: (Synset('swim.v.01'), Synset('walk.v.01'))\n","LCS for 'Synset('swim.v.01')' and 'Synset('walk.v.01')': [Synset('travel.v.01')]\n","Path Similarity: 0.3333333333333333\n","Leacock-Chodorow Similarity: 0.5936585841628025\n","Wu-Palmer Similarity: 0.3333333333333333\n","Lin Similarity: 0.4910052007916556\n","\n","Computing LCS and Similarities for pair: (Synset('girl.n.01'), Synset('male_child.n.01'))\n","LCS for 'Synset('girl.n.01')' and 'Synset('male_child.n.01')': [Synset('person.n.01')]\n","Path Similarity: 0.16666666666666666\n","Leacock-Chodorow Similarity: 0.5074317444173395\n","Wu-Palmer Similarity: 0.631578947368421\n","Lin Similarity: 0.2927280671561499\n","\n","Computing LCS and Similarities for pair: (Synset('girl.n.01'), Synset('woman.n.01'))\n","LCS for 'Synset('girl.n.01')' and 'Synset('woman.n.01')': [Synset('woman.n.01')]\n","Path Similarity: 0.5\n","Leacock-Chodorow Similarity: 0.8094485875732267\n","Wu-Palmer Similarity: 0.631578947368421\n","Lin Similarity: 0.9067798595489287\n","\n","Computing LCS and Similarities for pair: (Synset('male_child.n.01'), Synset('woman.n.01'))\n","LCS for 'Synset('male_child.n.01')' and 'Synset('woman.n.01')': [Synset('person.n.01')]\n","Path Similarity: 0.2\n","Leacock-Chodorow Similarity: 0.5575533219658061\n","Wu-Palmer Similarity: 0.6666666666666666\n","Lin Similarity: 0.31842335630818425\n"]}],"source":["# We get the value needed to normalize Leacock-Chodorow Similarity:\n","norm=wn.synset('historic_period.n.01').lch_similarity(wn.synset('historic_period.n.01'), ic_brown) # historic_period is an arbitrary choice here\n","print(f'The normalizing value for Leacock-Chodorow is:  {norm}')\n","\n","# least common subsummer and similarities\n","def compute_similarities(synset1,synset2):\n","\n","  #we print the LCS\n","  lcs = synset1.lowest_common_hypernyms(synset2)\n","  print(f\"LCS for '{synset1}' and '{synset2}': {lcs}\")\n","\n","  # Compute Path Similarity\n","  print(f\"Path Similarity: {synset1.path_similarity(synset2)}\")\n","\n","  # Compute Leacock-Chodorow Similarity\n","  print(f\"Leacock-Chodorow Similarity: {synset1.lch_similarity(synset2)/norm}\")\n","\n","  # Compute Wu-Palmer Similarity\n","  print(f\"Wu-Palmer Similarity: {synset1.wup_similarity(synset2)}\")\n","\n","  # Compute Lin Similarity (requires information content)\n","  try:\n","    lin_similarity = synset1.lin_similarity(synset2, ic_brown)\n","    if lin_similarity:\n","      print(f\"Lin Similarity: {synset1.lin_similarity(synset2, ic_brown)}\", end = \"\\n\")\n","    else:\n","      print(\"Lin Similarity: Not available\")\n","  except:\n","    print(\"Lin Similarity: Not available\")\n","\n","\n","for pair in valid_pairs:\n","  print(f'\\nComputing LCS and Similarities for pair: {pair}')\n","  compute_similarities(*pair)"]},{"cell_type":"markdown","metadata":{"id":"Ey7HSru0MZii"},"source":["*What similarity seems better?*\n","\n","This question is particularly hard because the answer may be dependant on the scenario. What can be said in a general manner is that the Path Similarity could get a misleading result because it doesn't account for the depth of the tree. A bigger tree will have more synsets, meaning more hyrarchy, resulting on the same synsets being more nodes away.\n","\n","An other thing we could say is that Lin Similarity requires further inspection and relies on the amount and quality of the corpus where you compute the information. If you were to use a biased corpus or an outdated one you could be missing certain relationships. On the other hand, if we use a good database and fairly common words we will get great results. An example of this is the woman-girl analysis where it gets the higher similarity reflecting greater sensibility to their close relationship.\n","\n","Both, Leacock-Chodorow and Wu-Palmer factor in the hirarchy of the tree and do certain normalization atending the complexity and depth. This is great and improves the results when compared to the simple Path Similarity. Leacock makes sure that two synset near the top of the tree get more penalised, which is better because this terms tend to be broader. On its side, Wu-Palmer uses their Lowest Shared Ancestor which is more related to our intuitive sense of similarity. A shared inconvenience of this methods is that they don't take into account the real usage of the words in real texts, contrary to Lin simmilarity.\n","\n","To sum up, all of them are superior to Path similarity and depending on the availability and quality of information it could be better to use Lin simmilarity or one between Leacock-Chodorow or Wu-Palmer similarity.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python (ihlt)","language":"python","name":"ihlt"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
